{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29970614",
   "metadata": {},
   "source": [
    "Rag example usage with Pydantic AI & ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86708292",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fastapi\n",
    "%pip install pydantic_ai\n",
    "%pip install chromadb\n",
    "%pip install python_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7544122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from python_dotenv import load_dotenv\n",
    "\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import nest_asyncio\n",
    "import requests\n",
    "from chromadb.api.models.Collection import Collection\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85c636f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n",
      "Inserted 15 documents into vector store\n",
      "{\n",
      "    \"ids\": [\n",
      "        \"d794baa2-0efe-4418-b30e-84b46cc45d55\",\n",
      "        \"abd8a12b-b100-46aa-8133-a4a1b7625214\",\n",
      "        \"2d4aba26-eaad-4973-84e4-516968a983d1\",\n",
      "        \"504f97ce-7834-4885-9ac8-e7c364868e2c\",\n",
      "        \"b0279786-3165-4466-93be-7f44faa7b52d\",\n",
      "        \"63d2d9a8-d356-4288-bc07-89a21c353fa2\",\n",
      "        \"9f3cd0f9-8162-4e29-8203-b7add2589e38\",\n",
      "        \"9e24e60b-4533-4cff-a89a-b289687b0570\",\n",
      "        \"c79fd81e-08c5-4fcf-81e5-da80ed26e090\",\n",
      "        \"6757fd63-bcff-4430-8730-1118d0415278\",\n",
      "        \"62644821-f829-48ea-bdf7-8df200ddd6e6\",\n",
      "        \"c09acf9a-4e1e-497d-86db-cca5d56e5ae2\",\n",
      "        \"e96ed035-798a-4579-991f-919a64e15763\",\n",
      "        \"30d57dfa-bf4f-4818-886f-c982e1786f8d\",\n",
      "        \"ba85e386-cef6-4852-ae0c-c851fa9f9da1\"\n",
      "    ],\n",
      "    \"embeddings\": null,\n",
      "    \"documents\": [\n",
      "        \"Python er et h\\u00f8jniveau programmeringssprog skabt af Guido van Rossum i 1991. Det er kendt for sin enkle og l\\u00e6sbare syntax der minder om naturligt sprog. Python bruger indrykning til at definere kodeblokke i stedet for kr\\u00f8llede parenteser. Sproget underst\\u00f8tter flere programmeringsparadigmer inklusiv objektorienteret, funktionel og procedural programmering. Python har en omfattende standardbibliotek der d\\u00e6kker alt fra filh\\u00e5ndtering til netv\\u00e6rkskommunikation. Variable i Python er dynamisk typede, hvilket betyder at du ikke beh\\u00f8ver at deklarere typen eksplicit. Python har indbyggede datatyper som strings, integers, floats, lists, tuples, dictionaries og sets. Funktioner defineres med def keyword og kan tage b\\u00e5de positionelle og keyword argumenter. Python underst\\u00f8tter ogs\\u00e5 list comprehensions der giver en kortfattet m\\u00e5de at skabe lister p\\u00e5. Error handling g\\u00f8res med try-except blokke der fanger exceptions. Python 3 er den nuv\\u00e6rende version og har v\\u00e6sentlige forbedringer over Python 2 inklusiv bedre Unicode support og print som funktion.\",\n",
      "        \"FastAPI er et moderne, hurtigt web framework til at bygge APIs med Python baseret p\\u00e5 standard Python type hints. Det blev skabt af Sebasti\\u00e1n Ram\\u00edrez og er bygget oven p\\u00e5 Starlette for web delen og Pydantic for data delen. FastAPI genererer automatisk OpenAPI dokumentation der kan tilg\\u00e5s via /docs endpoint med Swagger UI eller /redoc for ReDoc interface. Frameworket bruger Python type annotations til automatisk request validering, serialisering og dokumentation. FastAPI underst\\u00f8tter asynkron programmering med async/await syntax hvilket g\\u00f8r det ekstremt performant. Dependency injection systemet i FastAPI g\\u00f8r det nemt at dele logik mellem endpoints og h\\u00e5ndtere authentication, database connections og andre afh\\u00e6ngigheder. Path parameters defineres direkte i route decorator mens query parameters defineres som funktionsparametre. Request body validering sker automatisk gennem Pydantic models der ogs\\u00e5 bruges til response models. FastAPI har indbygget support for WebSockets, background tasks, CORS middleware og file uploads. Testing af FastAPI applikationer er nemt med TestClient fra starlette.testclient.\",\n",
      "        \"ChromaDB er en open-source embedding database designet til at v\\u00e6re let at bruge og ikke kr\\u00e6ve kompleks ops\\u00e6tning. Den fungerer som en vector database der gemmer og s\\u00f8ger i embeddings genereret fra tekst, billeder eller andre data. ChromaDB kan k\\u00f8re in-memory til udvikling eller persistent til produktion ved at specificere en sti. Collections i ChromaDB fungerer som tabeller og kan have associeret metadata for filtrering. N\\u00e5r du tilf\\u00f8jer dokumenter til ChromaDB, kan du enten provide dine egne embeddings eller lade ChromaDB generere dem automatisk ved hj\\u00e6lp af default embedding function. Query operationer bruger cosine similarity eller andre distance metrics til at finde de mest relevante dokumenter. ChromaDB underst\\u00f8tter b\\u00e5de exact nearest neighbor search og approximate nearest neighbor search for bedre performance p\\u00e5 store datasets. Metadata filtering lader dig kombinere vector search med traditionel filtrering p\\u00e5 felter som dato, kategori eller tags. ChromaDB kan bruges med forskellige embedding models inklusiv OpenAI embeddings, Sentence Transformers og custom models. Update og delete operationer underst\\u00f8ttes ogs\\u00e5 s\\u00e5 du kan modificere eksisterende dokumenter. ChromaDB integrerer godt med LangChain og andre LLM frameworks.\",\n",
      "        \"Retrieval-Augmented Generation er en teknik der kombinerer information retrieval med language model generation for at give mere faktuelle og opdaterede svar. RAG l\\u00f8ser problemet med at LLMs kun kender til data fra deres tr\\u00e6ningsperiode og kan hallucinere fakta. Arkitekturen best\\u00e5r af tre hovedkomponenter: en vector database med embeddings af dokumenter, en retrieval komponent der finder relevante dokumenter, og en generative komponent der syntetiserer svar baseret p\\u00e5 de fundne dokumenter. I praksis fungerer RAG ved f\\u00f8rst at embedde brugerens query, derefter s\\u00f8ge efter lignende embeddings i vector databasen, og endelig give de fundne dokumenter som kontekst til LLM sammen med det originale sp\\u00f8rgsm\\u00e5l. Chunk size er kritisk - for sm\\u00e5 chunks mister kontekst mens for store chunks indeholder irrelevant information. Overlap mellem chunks hj\\u00e6lper med at bevare kontekst p\\u00e5 tv\\u00e6rs af boundaries. Re-ranking kan forbedre resultaterne ved at sortere de fundne dokumenter efter relevans f\\u00f8r de sendes til LLM. Hybrid search kombinerer semantic search med keyword search for bedre precision. RAG kan ogs\\u00e5 bruge query expansion hvor det originale sp\\u00f8rgsm\\u00e5l omformuleres p\\u00e5 flere m\\u00e5der for at fange flere relevante dokumenter.\",\n",
      "        \"Docker er en platform til at udvikle, shippe og k\\u00f8re applikationer i containers. Containers pakker applikationen og alle dens dependencies sammen s\\u00e5 den k\\u00f8rer identisk p\\u00e5 tv\\u00e6rs af milj\\u00f8er. En Dockerfile er et script med instruktioner til at bygge et Docker image. FROM instruktionen specificerer base image, RUN udf\\u00f8rer kommandoer, COPY kopierer filer ind i image, og CMD definerer default kommando n\\u00e5r container startes. Multi-stage builds reducerer image st\\u00f8rrelse ved at bruge flere FROM statements og kun kopiere n\\u00f8dvendige artifacts til final image. .dockerignore filen specificerer hvilke filer der ikke skal inkluderes i build context. Docker Compose orkestrer multi-container applikationer ved at definere services, networks og volumes i en docker-compose.yml fil. Volumes bevarer data selv n\\u00e5r containers stoppes eller slettes. Networks lader containers kommunikere sikkert med hinanden. Environment variables kan passes til containers via ENV i Dockerfile eller environment i docker-compose. Health checks verificerer at containeren k\\u00f8rer korrekt. Docker Hub er et registry til at dele og distribuere images. Best practices inkluderer at bruge officielle base images, minimere antal layers, k\\u00f8re containers som non-root user, og scanne images for s\\u00e5rbarheder.\",\n",
      "        \"REST st\\u00e5r for Representational State Transfer og er en arkitektonisk stil for at designe networked applications. RESTful APIs bruger HTTP requests til at udf\\u00f8re CRUD operationer: Create via POST, Read via GET, Update via PUT eller PATCH, og Delete via DELETE. URLs i REST repr\\u00e6senterer ressourcer ikke actions - brug /users ikke /getUsers. Ressourcer b\\u00f8r v\\u00e6re navngivet med substantiver i flertal som /products /orders /customers. Nested ressourcer kan repr\\u00e6senteres hierarkisk som /users/123/orders. Query parameters bruges til filtrering, sortering og pagination som /products?category=electronics&sort=price&page=2. HTTP status codes kommunikerer resultatet: 200 OK for success, 201 Created for nye ressourcer, 400 Bad Request for invalid input, 401 Unauthorized for authentication fejl, 404 Not Found for ikke-eksisterende ressourcer, 500 Internal Server Error for server fejl. Response bodies b\\u00f8r returnere JSON eller XML konsistent. Versioning kan h\\u00e5ndteres via URL path /api/v1/users eller via headers. HATEOAS principper inkluderer links til relaterede ressourcer i responses. Idempotency betyder at samme request kan udf\\u00f8res flere gange med samme resultat - GET PUT og DELETE b\\u00f8r v\\u00e6re idempotente. Rate limiting beskytter API mod overload. API documentation b\\u00f8r inkludere endpoints, parameters, request/response examples og authentication requirements.\",\n",
      "        \"PostgreSQL er et kraftfuldt open-source objekt-relationelt database system med over 35 \\u00e5rs aktiv udvikling. Det er kendt for sin robusthed, feature set og performance. PostgreSQL underst\\u00f8tter ACID transactions hvilket garanterer data integritet selv ved system fejl. Data types i PostgreSQL inkluderer standard SQL types samt advanced types som JSON, JSONB, arrays, hstore, geometric types og custom types. JSONB er s\\u00e6rligt popul\\u00e6rt da det kombinerer fleksibiliteten af NoSQL med SQL queries. Indexes forbedrer query performance - B-tree er default men PostgreSQL underst\\u00f8tter ogs\\u00e5 hash, GiST, SP-GiST, GIN og BRIN indexes. Full-text search er indbygget med st\\u00f8tte for stemming, ranking og forskellige sprog. Constraints h\\u00e5ndh\\u00e6ver data integritet: PRIMARY KEY for unikke identifiers, FOREIGN KEY for relationer, UNIQUE for unikke v\\u00e6rdier, CHECK for custom validering. Views er saved queries der kan behandles som virtuelle tabeller. Materialized views cacher query resultater for performance. Triggers er funktioner der automatisk udf\\u00f8res ved events som INSERT UPDATE eller DELETE. Stored procedures og functions kan skrives i PL/pgSQL SQL Python eller andre sprog. Partitioning opdeler store tabeller i mindre stykker for bedre performance. Replication giver high availability ved at kopiere data til andre servere.\",\n",
      "        \"Git er et distribueret version control system skabt af Linus Torvalds i 2005. Hver udvikler har en fuld kopi af repository historikken lokalt. Et Git repository initialiseres med git init eller clones fra remote med git clone. Working directory indeholder de faktiske filer, staging area holder \\u00e6ndringer klar til commit, og repository indeholder committed historie. git add tilf\\u00f8jer filer til staging area, git commit gemmer \\u00e6ndringer med en besked, git push sender commits til remote repository, git pull henter og merger \\u00e6ndringer fra remote. Branches lader flere udviklere arbejde parallelt uden at p\\u00e5virke hinanden - git branch lister branches, git checkout -b opretter ny branch. Merging kombinerer \\u00e6ndringer fra forskellige branches med git merge, mens rebase giver en line\\u00e6r historie. Merge conflicts opst\\u00e5r n\\u00e5r samme linjer er \\u00e6ndret i forskellige branches og skal l\\u00f8ses manuelt. git status viser working directory status, git log viser commit historie, git diff viser \\u00e6ndringer. Remote repositories som GitHub eller GitLab fungerer som centrale servere til collaboration. Pull requests er en m\\u00e5de at review og diskutere \\u00e6ndringer f\\u00f8r de merges. .gitignore specificerer filer Git skal ignorere som node_modules eller .env filer. Tags markerer vigtige points i historien som releases.\",\n",
      "        \"JSON Web Token er en kompakt URL-safe m\\u00e5de at repr\\u00e6sentere claims mellem to parter. JWT best\\u00e5r af tre dele adskilt af punktummer: header, payload og signature. Header indeholder token type og hashing algoritme typisk HS256 eller RS256. Payload indeholder claims som user ID, expiration time, issuer og custom data. Signature sikrer at token ikke er blevet modificeret og genereres ved at hashe header og payload med en secret key. JWT er stateless hvilket betyder serveren ikke beh\\u00f8ver at gemme session information. Efter login genererer serveren et JWT som sendes til klienten typisk i en HTTP header eller cookie. Klienten inkluderer JWT i Authorization header som Bearer token ved efterf\\u00f8lgende requests. Serveren verificerer JWT signature og checker expiration f\\u00f8r den tillader adgang til beskyttede ressourcer. Refresh tokens er l\\u00e6ngere-lived tokens brugt til at f\\u00e5 nye access tokens n\\u00e5r de udl\\u00f8ber. Best practices inkluderer at bruge HTTPS altid, holde expiration times korte, gemme secrets sikkert, validere alle claims, og bruge strong algoritmer. JWT b\\u00f8r ikke indeholde sensitive data da payload er kun base64 encoded ikke encrypted. For h\\u00f8jere sikkerhed kan tokens ogs\\u00e5 encrypts med JWE. Revocation af JWT er udfordrende pga stateless nature men kan h\\u00e5ndteres med blacklists eller korte expiration times.\",\n",
      "        \"Kubernetes er en open-source platform til automating deployment, scaling og management af containerized applications. Det blev oprindeligt udviklet af Google og er nu maintained af Cloud Native Computing Foundation. Kubernetes arkitekturen best\\u00e5r af en control plane og worker nodes. Control plane komponenter inkluderer API server som frontend, etcd for distributed key-value storage, scheduler som tildeler pods til nodes, og controller manager. Worker nodes k\\u00f8rer kubelet agent, container runtime som Docker eller containerd, og kube-proxy for netv\\u00e6rk. Pods er den mindste deployable unit i Kubernetes og kan indeholde en eller flere t\\u00e6t koblede containers. Deployments h\\u00e5ndterer pod lifecycle og rolling updates. Services eksponerer pods til netv\\u00e6rket og giver load balancing. ConfigMaps og Secrets gemmer konfiguration og sensitive data adskilt fra application code. Persistent Volumes giver storage til pods der overlever pod restarts. Namespaces giver isolation mellem forskellige teams eller milj\\u00f8er. Ingress h\\u00e5ndterer external HTTP/HTTPS routing til services. Horizontal Pod Autoscaler automatisk scaler pod antal baseret p\\u00e5 CPU eller custom metrics. Labels og selectors bruges til at organisere og v\\u00e6lge resources. kubectl er command-line tool til at interagere med clusters.\",\n",
      "        \"Microservices arkitektur opdeler applikationer i sm\\u00e5 uafh\\u00e6ngige services der hver h\\u00e5ndterer en specifik business capability. Hver microservice har sin egen database og kan deployes uafh\\u00e6ngigt hvilket giver h\\u00f8j skalerbarhed og fejltolerance. Services kommunikerer typisk via REST APIs, gRPC eller message queues som RabbitMQ eller Kafka. API Gateway fungerer som single entry point for klienter og h\\u00e5ndterer routing, authentication og rate limiting. Service discovery mekanismer som Consul eller Eureka lader services finde hinanden dynamisk. Circuit breaker pattern forhindrer cascade failures ved at afbryde requests til failing services. Eventual consistency accepteres da distribuerede transaktioner er komplekse - Saga pattern koordinerer transaktioner p\\u00e5 tv\\u00e6rs af services. Hver microservice b\\u00f8r f\\u00f8lge single responsibility principle og v\\u00e6re loosely coupled. Distributed tracing med tools som Jaeger hj\\u00e6lper med at debugge requests der sp\\u00e6nder over multiple services. Centralized logging aggregerer logs fra alle services til lettere monitoring. Container orchestration med Kubernetes er popul\\u00e6rt til deployment. Challenges inkluderer \\u00f8get kompleksitet, network latency, data consistency og testing af distribuerede systemer. Best practices inkluderer at definere klare service boundaries, implementere comprehensive monitoring, automatisere deployments og have god documentation.\",\n",
      "        \"Continuous Integration og Continuous Deployment er practices der automatiserer software delivery processen. CI betyder at developers integrerer kode til shared repository flere gange dagligt hvor hver integration verificeres af automated builds og tests. CD udvider CI til automatisk at deploye alle kode \\u00e6ndringer til production efter at de passer tests. En typisk CI/CD pipeline starter med source control trigger n\\u00e5r kode pushes. Build stage compiler kode og resolver dependencies. Test stage k\\u00f8rer unit tests, integration tests og end-to-end tests. Code quality checks inkluderer linting, security scanning og code coverage analysis. Artifact creation pakker applikationen i deployable format som Docker image. Deployment stage deployer til forskellige milj\\u00f8er - ofte f\\u00f8rst staging derefter production. Rollback mekanismer lader dig hurtigt vende tilbage til previous version ved fejl. Popular CI/CD tools inkluderer Jenkins, GitLab CI, GitHub Actions, CircleCI og Travis CI. Pipeline configuration defineres typisk i YAML filer i repository. Environment variables og secrets manages sikkert gennem CI/CD platform. Monitoring og alerting notificerer teams om pipeline failures. Blue-green deployments og canary releases minimerer risiko ved at route kun en del af traffic til ny version f\\u00f8rst.\",\n",
      "        \"SQL query optimization er kritisk for database performance is\\u00e6r p\\u00e5 store datasets. EXPLAIN eller EXPLAIN ANALYZE kommandoer viser query execution plan og hj\\u00e6lper med at identificere bottlenecks. Indexes er det vigtigste optimeringsv\\u00e6rkt\\u00f8j - de virker som en bog index og lader databasen hurtigt finde rows uden at scanne hele tabellen. B-tree indexes er default og fungerer godt til equality og range queries. Composite indexes p\\u00e5 multiple columns kan optimere queries med WHERE clauses p\\u00e5 flere felter men r\\u00e6kkef\\u00f8lgen af columns er vigtig. SELECT statements b\\u00f8r kun hente n\\u00f8dvendige columns ikke SELECT * da dette reducerer I/O. WHERE clauses b\\u00f8r filtrere s\\u00e5 tidligt som muligt for at reducere data m\\u00e6ngde. JOIN operations kan v\\u00e6re dyre - INNER JOIN er typisk hurtigst, mens subqueries ofte kan omskrives til JOINs for bedre performance. Query planner bruger statistics om data distribution til at v\\u00e6lge optimal execution strategy s\\u00e5 ANALYZE kommando b\\u00f8r k\\u00f8res regelm\\u00e6ssigt. Pagination med LIMIT og OFFSET er ineffektiv p\\u00e5 h\\u00f8je offset values - keyset pagination med WHERE id > last_seen_id er hurtigere. Denormalization kan forbedre read performance ved at reducere JOINs men \\u00f8ger write kompleksitet. Materialized views cacher komplekse query resultater. Query caching p\\u00e5 application level reducerer database load.\",\n",
      "        \"OAuth 2.0 er en authorization framework der lader third-party applications f\\u00e5 limited access til HTTP services. Det adskiller authentication fra authorization ved at bruge access tokens i stedet for credentials. OAuth definerer fire roller: resource owner (user), client (application), authorization server (authenticator), og resource server (API). Authorization code flow er mest sikker for web apps: user redirectes til authorization server, logger ind, authorization server redirecter tilbage til client med authorization code, client bytter code til access token. Implicit flow var tidligere brugt til browser-based apps men er nu deprecated til fordel for authorization code flow med PKCE. Client credentials flow bruges til server-to-server communication hvor der ikke er en user involved. Resource owner password flow giver client direkte adgang til user credentials og b\\u00f8r kun bruges i trusted applications. Access tokens er typisk short-lived mens refresh tokens er longer-lived og bruges til at f\\u00e5 nye access tokens. Scopes definerer permissions som client requester - for eksempel read:user eller write:posts. State parameter beskytter mod CSRF attacks. OAuth 2.0 specificerer ikke token format men JWT er almindeligt brugt. OpenID Connect bygger p\\u00e5 OAuth 2.0 og tilf\\u00f8jer authentication layer med ID tokens.\",\n",
      "        \"Redis er en in-memory data structure store brugt som database, cache og message broker. Som cache reducerer Redis load p\\u00e5 prim\\u00e6r database ved at gemme frequently accessed data i hukommelsen. Data structures i Redis inkluderer strings, hashes, lists, sets, sorted sets, bitmaps og HyperLogLogs. Cache-aside pattern er mest common: application checker Redis f\\u00f8rst, ved cache miss hentes data fra database og gemmes i Redis. Write-through cache opdaterer b\\u00e5de cache og database samtidigt hvilket sikrer consistency. Write-behind cache opdaterer kun cache f\\u00f8rst og synkroniserer til database asynkront hvilket giver bedre write performance men risikerer data loss. Keys b\\u00f8r navngives konsistent med patterns som user:1234:profile. Expiration kan s\\u00e6ttes med EXPIRE kommando for automatisk at rydde gamle data. Eviction policies som LRU (Least Recently Used) styrer hvad der slettes n\\u00e5r memory er fyldt. Redis persistence options inkluderer RDB snapshots og AOF (Append Only File) logging. Redis Cluster giver horizontal scaling ved at distribuere data across multiple nodes. Pub/Sub messaging lader services subscribe til channels for real-time events. Redis Streams underst\\u00f8tter consumer groups for distributed processing. Transaction support med MULTI og EXEC sikrer atomic operations.\"\n",
      "    ],\n",
      "    \"uris\": null,\n",
      "    \"included\": [\n",
      "        \"metadatas\",\n",
      "        \"documents\"\n",
      "    ],\n",
      "    \"data\": null,\n",
      "    \"metadatas\": [\n",
      "        {\n",
      "            \"title\": \"Python Grundl\\u00e6ggende og Syntax\",\n",
      "            \"source\": \"Python Official Documentation 3.11, Introduction to Python\",\n",
      "            \"content\": \"Python er et h\\u00f8jniveau programmeringssprog skabt af Guido van Rossum i 1991. Det er kendt for sin enkle og l\\u00e6sbare syntax der minder om naturligt sprog. Python bruger indrykning til at definere kodeblokke i stedet for kr\\u00f8llede parenteser. Sproget underst\\u00f8tter flere programmeringsparadigmer inklusiv objektorienteret, funktionel og procedural programmering. Python har en omfattende standardbibliotek der d\\u00e6kker alt fra filh\\u00e5ndtering til netv\\u00e6rkskommunikation. Variable i Python er dynamisk typede, hvilket betyder at du ikke beh\\u00f8ver at deklarere typen eksplicit. Python har indbyggede datatyper som strings, integers, floats, lists, tuples, dictionaries og sets. Funktioner defineres med def keyword og kan tage b\\u00e5de positionelle og keyword argumenter. Python underst\\u00f8tter ogs\\u00e5 list comprehensions der giver en kortfattet m\\u00e5de at skabe lister p\\u00e5. Error handling g\\u00f8res med try-except blokke der fanger exceptions. Python 3 er den nuv\\u00e6rende version og har v\\u00e6sentlige forbedringer over Python 2 inklusiv bedre Unicode support og print som funktion.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"FastAPI Framework og Moderne API Udvikling\",\n",
      "            \"source\": \"FastAPI Official Documentation 0.104, FastAPI Guide by Sebasti\\u00e1n Ram\\u00edrez\",\n",
      "            \"content\": \"FastAPI er et moderne, hurtigt web framework til at bygge APIs med Python baseret p\\u00e5 standard Python type hints. Det blev skabt af Sebasti\\u00e1n Ram\\u00edrez og er bygget oven p\\u00e5 Starlette for web delen og Pydantic for data delen. FastAPI genererer automatisk OpenAPI dokumentation der kan tilg\\u00e5s via /docs endpoint med Swagger UI eller /redoc for ReDoc interface. Frameworket bruger Python type annotations til automatisk request validering, serialisering og dokumentation. FastAPI underst\\u00f8tter asynkron programmering med async/await syntax hvilket g\\u00f8r det ekstremt performant. Dependency injection systemet i FastAPI g\\u00f8r det nemt at dele logik mellem endpoints og h\\u00e5ndtere authentication, database connections og andre afh\\u00e6ngigheder. Path parameters defineres direkte i route decorator mens query parameters defineres som funktionsparametre. Request body validering sker automatisk gennem Pydantic models der ogs\\u00e5 bruges til response models. FastAPI har indbygget support for WebSockets, background tasks, CORS middleware og file uploads. Testing af FastAPI applikationer er nemt med TestClient fra starlette.testclient.\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"ChromaDB er en open-source embedding database designet til at v\\u00e6re let at bruge og ikke kr\\u00e6ve kompleks ops\\u00e6tning. Den fungerer som en vector database der gemmer og s\\u00f8ger i embeddings genereret fra tekst, billeder eller andre data. ChromaDB kan k\\u00f8re in-memory til udvikling eller persistent til produktion ved at specificere en sti. Collections i ChromaDB fungerer som tabeller og kan have associeret metadata for filtrering. N\\u00e5r du tilf\\u00f8jer dokumenter til ChromaDB, kan du enten provide dine egne embeddings eller lade ChromaDB generere dem automatisk ved hj\\u00e6lp af default embedding function. Query operationer bruger cosine similarity eller andre distance metrics til at finde de mest relevante dokumenter. ChromaDB underst\\u00f8tter b\\u00e5de exact nearest neighbor search og approximate nearest neighbor search for bedre performance p\\u00e5 store datasets. Metadata filtering lader dig kombinere vector search med traditionel filtrering p\\u00e5 felter som dato, kategori eller tags. ChromaDB kan bruges med forskellige embedding models inklusiv OpenAI embeddings, Sentence Transformers og custom models. Update og delete operationer underst\\u00f8ttes ogs\\u00e5 s\\u00e5 du kan modificere eksisterende dokumenter. ChromaDB integrerer godt med LangChain og andre LLM frameworks.\",\n",
      "            \"title\": \"ChromaDB Vector Database og Embeddings\",\n",
      "            \"source\": \"ChromaDB Documentation v0.4.15, Getting Started with Vector Databases\"\n",
      "        },\n",
      "        {\n",
      "            \"source\": \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, Lewis et al. 2020\",\n",
      "            \"title\": \"RAG Arkitektur og Implementation\",\n",
      "            \"content\": \"Retrieval-Augmented Generation er en teknik der kombinerer information retrieval med language model generation for at give mere faktuelle og opdaterede svar. RAG l\\u00f8ser problemet med at LLMs kun kender til data fra deres tr\\u00e6ningsperiode og kan hallucinere fakta. Arkitekturen best\\u00e5r af tre hovedkomponenter: en vector database med embeddings af dokumenter, en retrieval komponent der finder relevante dokumenter, og en generative komponent der syntetiserer svar baseret p\\u00e5 de fundne dokumenter. I praksis fungerer RAG ved f\\u00f8rst at embedde brugerens query, derefter s\\u00f8ge efter lignende embeddings i vector databasen, og endelig give de fundne dokumenter som kontekst til LLM sammen med det originale sp\\u00f8rgsm\\u00e5l. Chunk size er kritisk - for sm\\u00e5 chunks mister kontekst mens for store chunks indeholder irrelevant information. Overlap mellem chunks hj\\u00e6lper med at bevare kontekst p\\u00e5 tv\\u00e6rs af boundaries. Re-ranking kan forbedre resultaterne ved at sortere de fundne dokumenter efter relevans f\\u00f8r de sendes til LLM. Hybrid search kombinerer semantic search med keyword search for bedre precision. RAG kan ogs\\u00e5 bruge query expansion hvor det originale sp\\u00f8rgsm\\u00e5l omformuleres p\\u00e5 flere m\\u00e5der for at fange flere relevante dokumenter.\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"Docker er en platform til at udvikle, shippe og k\\u00f8re applikationer i containers. Containers pakker applikationen og alle dens dependencies sammen s\\u00e5 den k\\u00f8rer identisk p\\u00e5 tv\\u00e6rs af milj\\u00f8er. En Dockerfile er et script med instruktioner til at bygge et Docker image. FROM instruktionen specificerer base image, RUN udf\\u00f8rer kommandoer, COPY kopierer filer ind i image, og CMD definerer default kommando n\\u00e5r container startes. Multi-stage builds reducerer image st\\u00f8rrelse ved at bruge flere FROM statements og kun kopiere n\\u00f8dvendige artifacts til final image. .dockerignore filen specificerer hvilke filer der ikke skal inkluderes i build context. Docker Compose orkestrer multi-container applikationer ved at definere services, networks og volumes i en docker-compose.yml fil. Volumes bevarer data selv n\\u00e5r containers stoppes eller slettes. Networks lader containers kommunikere sikkert med hinanden. Environment variables kan passes til containers via ENV i Dockerfile eller environment i docker-compose. Health checks verificerer at containeren k\\u00f8rer korrekt. Docker Hub er et registry til at dele og distribuere images. Best practices inkluderer at bruge officielle base images, minimere antal layers, k\\u00f8re containers som non-root user, og scanne images for s\\u00e5rbarheder.\",\n",
      "            \"title\": \"Docker Containerization og Best Practices\",\n",
      "            \"source\": \"Docker Documentation, Best Practices for Writing Dockerfiles\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"REST st\\u00e5r for Representational State Transfer og er en arkitektonisk stil for at designe networked applications. RESTful APIs bruger HTTP requests til at udf\\u00f8re CRUD operationer: Create via POST, Read via GET, Update via PUT eller PATCH, og Delete via DELETE. URLs i REST repr\\u00e6senterer ressourcer ikke actions - brug /users ikke /getUsers. Ressourcer b\\u00f8r v\\u00e6re navngivet med substantiver i flertal som /products /orders /customers. Nested ressourcer kan repr\\u00e6senteres hierarkisk som /users/123/orders. Query parameters bruges til filtrering, sortering og pagination som /products?category=electronics&sort=price&page=2. HTTP status codes kommunikerer resultatet: 200 OK for success, 201 Created for nye ressourcer, 400 Bad Request for invalid input, 401 Unauthorized for authentication fejl, 404 Not Found for ikke-eksisterende ressourcer, 500 Internal Server Error for server fejl. Response bodies b\\u00f8r returnere JSON eller XML konsistent. Versioning kan h\\u00e5ndteres via URL path /api/v1/users eller via headers. HATEOAS principper inkluderer links til relaterede ressourcer i responses. Idempotency betyder at samme request kan udf\\u00f8res flere gange med samme resultat - GET PUT og DELETE b\\u00f8r v\\u00e6re idempotente. Rate limiting beskytter API mod overload. API documentation b\\u00f8r inkludere endpoints, parameters, request/response examples og authentication requirements.\",\n",
      "            \"source\": \"RESTful Web Services, Richardson & Ruby 2007, O'Reilly Media\",\n",
      "            \"title\": \"REST API Design Principper og Conventions\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"PostgreSQL Database Administration og Features\",\n",
      "            \"content\": \"PostgreSQL er et kraftfuldt open-source objekt-relationelt database system med over 35 \\u00e5rs aktiv udvikling. Det er kendt for sin robusthed, feature set og performance. PostgreSQL underst\\u00f8tter ACID transactions hvilket garanterer data integritet selv ved system fejl. Data types i PostgreSQL inkluderer standard SQL types samt advanced types som JSON, JSONB, arrays, hstore, geometric types og custom types. JSONB er s\\u00e6rligt popul\\u00e6rt da det kombinerer fleksibiliteten af NoSQL med SQL queries. Indexes forbedrer query performance - B-tree er default men PostgreSQL underst\\u00f8tter ogs\\u00e5 hash, GiST, SP-GiST, GIN og BRIN indexes. Full-text search er indbygget med st\\u00f8tte for stemming, ranking og forskellige sprog. Constraints h\\u00e5ndh\\u00e6ver data integritet: PRIMARY KEY for unikke identifiers, FOREIGN KEY for relationer, UNIQUE for unikke v\\u00e6rdier, CHECK for custom validering. Views er saved queries der kan behandles som virtuelle tabeller. Materialized views cacher query resultater for performance. Triggers er funktioner der automatisk udf\\u00f8res ved events som INSERT UPDATE eller DELETE. Stored procedures og functions kan skrives i PL/pgSQL SQL Python eller andre sprog. Partitioning opdeler store tabeller i mindre stykker for bedre performance. Replication giver high availability ved at kopiere data til andre servere.\",\n",
      "            \"source\": \"PostgreSQL 15 Official Documentation, Chapter 1-5\"\n",
      "        },\n",
      "        {\n",
      "            \"source\": \"Pro Git Book 2nd Edition, Chacon & Straub 2023, Apress\",\n",
      "            \"content\": \"Git er et distribueret version control system skabt af Linus Torvalds i 2005. Hver udvikler har en fuld kopi af repository historikken lokalt. Et Git repository initialiseres med git init eller clones fra remote med git clone. Working directory indeholder de faktiske filer, staging area holder \\u00e6ndringer klar til commit, og repository indeholder committed historie. git add tilf\\u00f8jer filer til staging area, git commit gemmer \\u00e6ndringer med en besked, git push sender commits til remote repository, git pull henter og merger \\u00e6ndringer fra remote. Branches lader flere udviklere arbejde parallelt uden at p\\u00e5virke hinanden - git branch lister branches, git checkout -b opretter ny branch. Merging kombinerer \\u00e6ndringer fra forskellige branches med git merge, mens rebase giver en line\\u00e6r historie. Merge conflicts opst\\u00e5r n\\u00e5r samme linjer er \\u00e6ndret i forskellige branches og skal l\\u00f8ses manuelt. git status viser working directory status, git log viser commit historie, git diff viser \\u00e6ndringer. Remote repositories som GitHub eller GitLab fungerer som centrale servere til collaboration. Pull requests er en m\\u00e5de at review og diskutere \\u00e6ndringer f\\u00f8r de merges. .gitignore specificerer filer Git skal ignorere som node_modules eller .env filer. Tags markerer vigtige points i historien som releases.\",\n",
      "            \"title\": \"Git Version Control Workflow og Commands\"\n",
      "        },\n",
      "        {\n",
      "            \"source\": \"RFC 7519 - JSON Web Token (JWT) Standard, IETF\",\n",
      "            \"content\": \"JSON Web Token er en kompakt URL-safe m\\u00e5de at repr\\u00e6sentere claims mellem to parter. JWT best\\u00e5r af tre dele adskilt af punktummer: header, payload og signature. Header indeholder token type og hashing algoritme typisk HS256 eller RS256. Payload indeholder claims som user ID, expiration time, issuer og custom data. Signature sikrer at token ikke er blevet modificeret og genereres ved at hashe header og payload med en secret key. JWT er stateless hvilket betyder serveren ikke beh\\u00f8ver at gemme session information. Efter login genererer serveren et JWT som sendes til klienten typisk i en HTTP header eller cookie. Klienten inkluderer JWT i Authorization header som Bearer token ved efterf\\u00f8lgende requests. Serveren verificerer JWT signature og checker expiration f\\u00f8r den tillader adgang til beskyttede ressourcer. Refresh tokens er l\\u00e6ngere-lived tokens brugt til at f\\u00e5 nye access tokens n\\u00e5r de udl\\u00f8ber. Best practices inkluderer at bruge HTTPS altid, holde expiration times korte, gemme secrets sikkert, validere alle claims, og bruge strong algoritmer. JWT b\\u00f8r ikke indeholde sensitive data da payload er kun base64 encoded ikke encrypted. For h\\u00f8jere sikkerhed kan tokens ogs\\u00e5 encrypts med JWE. Revocation af JWT er udfordrende pga stateless nature men kan h\\u00e5ndteres med blacklists eller korte expiration times.\",\n",
      "            \"title\": \"JWT Authentication og Security\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"Kubernetes er en open-source platform til automating deployment, scaling og management af containerized applications. Det blev oprindeligt udviklet af Google og er nu maintained af Cloud Native Computing Foundation. Kubernetes arkitekturen best\\u00e5r af en control plane og worker nodes. Control plane komponenter inkluderer API server som frontend, etcd for distributed key-value storage, scheduler som tildeler pods til nodes, og controller manager. Worker nodes k\\u00f8rer kubelet agent, container runtime som Docker eller containerd, og kube-proxy for netv\\u00e6rk. Pods er den mindste deployable unit i Kubernetes og kan indeholde en eller flere t\\u00e6t koblede containers. Deployments h\\u00e5ndterer pod lifecycle og rolling updates. Services eksponerer pods til netv\\u00e6rket og giver load balancing. ConfigMaps og Secrets gemmer konfiguration og sensitive data adskilt fra application code. Persistent Volumes giver storage til pods der overlever pod restarts. Namespaces giver isolation mellem forskellige teams eller milj\\u00f8er. Ingress h\\u00e5ndterer external HTTP/HTTPS routing til services. Horizontal Pod Autoscaler automatisk scaler pod antal baseret p\\u00e5 CPU eller custom metrics. Labels og selectors bruges til at organisere og v\\u00e6lge resources. kubectl er command-line tool til at interagere med clusters.\",\n",
      "            \"source\": \"Kubernetes Documentation v1.28, Kubernetes Concepts\",\n",
      "            \"title\": \"Kubernetes Container Orchestration\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"Microservices arkitektur opdeler applikationer i sm\\u00e5 uafh\\u00e6ngige services der hver h\\u00e5ndterer en specifik business capability. Hver microservice har sin egen database og kan deployes uafh\\u00e6ngigt hvilket giver h\\u00f8j skalerbarhed og fejltolerance. Services kommunikerer typisk via REST APIs, gRPC eller message queues som RabbitMQ eller Kafka. API Gateway fungerer som single entry point for klienter og h\\u00e5ndterer routing, authentication og rate limiting. Service discovery mekanismer som Consul eller Eureka lader services finde hinanden dynamisk. Circuit breaker pattern forhindrer cascade failures ved at afbryde requests til failing services. Eventual consistency accepteres da distribuerede transaktioner er komplekse - Saga pattern koordinerer transaktioner p\\u00e5 tv\\u00e6rs af services. Hver microservice b\\u00f8r f\\u00f8lge single responsibility principle og v\\u00e6re loosely coupled. Distributed tracing med tools som Jaeger hj\\u00e6lper med at debugge requests der sp\\u00e6nder over multiple services. Centralized logging aggregerer logs fra alle services til lettere monitoring. Container orchestration med Kubernetes er popul\\u00e6rt til deployment. Challenges inkluderer \\u00f8get kompleksitet, network latency, data consistency og testing af distribuerede systemer. Best practices inkluderer at definere klare service boundaries, implementere comprehensive monitoring, automatisere deployments og have god documentation.\",\n",
      "            \"title\": \"Microservices Architecture Patterns\",\n",
      "            \"source\": \"Building Microservices, 2nd Edition, Sam Newman, O'Reilly 2021\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"Continuous Integration og Continuous Deployment er practices der automatiserer software delivery processen. CI betyder at developers integrerer kode til shared repository flere gange dagligt hvor hver integration verificeres af automated builds og tests. CD udvider CI til automatisk at deploye alle kode \\u00e6ndringer til production efter at de passer tests. En typisk CI/CD pipeline starter med source control trigger n\\u00e5r kode pushes. Build stage compiler kode og resolver dependencies. Test stage k\\u00f8rer unit tests, integration tests og end-to-end tests. Code quality checks inkluderer linting, security scanning og code coverage analysis. Artifact creation pakker applikationen i deployable format som Docker image. Deployment stage deployer til forskellige milj\\u00f8er - ofte f\\u00f8rst staging derefter production. Rollback mekanismer lader dig hurtigt vende tilbage til previous version ved fejl. Popular CI/CD tools inkluderer Jenkins, GitLab CI, GitHub Actions, CircleCI og Travis CI. Pipeline configuration defineres typisk i YAML filer i repository. Environment variables og secrets manages sikkert gennem CI/CD platform. Monitoring og alerting notificerer teams om pipeline failures. Blue-green deployments og canary releases minimerer risiko ved at route kun en del af traffic til ny version f\\u00f8rst.\",\n",
      "            \"title\": \"CI/CD Pipeline Implementation\",\n",
      "            \"source\": \"Continuous Delivery, Humble & Farley, Addison-Wesley 2010\"\n",
      "        },\n",
      "        {\n",
      "            \"source\": \"SQL Performance Explained, Markus Winand, 2012\",\n",
      "            \"title\": \"SQL Query Optimization Techniques\",\n",
      "            \"content\": \"SQL query optimization er kritisk for database performance is\\u00e6r p\\u00e5 store datasets. EXPLAIN eller EXPLAIN ANALYZE kommandoer viser query execution plan og hj\\u00e6lper med at identificere bottlenecks. Indexes er det vigtigste optimeringsv\\u00e6rkt\\u00f8j - de virker som en bog index og lader databasen hurtigt finde rows uden at scanne hele tabellen. B-tree indexes er default og fungerer godt til equality og range queries. Composite indexes p\\u00e5 multiple columns kan optimere queries med WHERE clauses p\\u00e5 flere felter men r\\u00e6kkef\\u00f8lgen af columns er vigtig. SELECT statements b\\u00f8r kun hente n\\u00f8dvendige columns ikke SELECT * da dette reducerer I/O. WHERE clauses b\\u00f8r filtrere s\\u00e5 tidligt som muligt for at reducere data m\\u00e6ngde. JOIN operations kan v\\u00e6re dyre - INNER JOIN er typisk hurtigst, mens subqueries ofte kan omskrives til JOINs for bedre performance. Query planner bruger statistics om data distribution til at v\\u00e6lge optimal execution strategy s\\u00e5 ANALYZE kommando b\\u00f8r k\\u00f8res regelm\\u00e6ssigt. Pagination med LIMIT og OFFSET er ineffektiv p\\u00e5 h\\u00f8je offset values - keyset pagination med WHERE id > last_seen_id er hurtigere. Denormalization kan forbedre read performance ved at reducere JOINs men \\u00f8ger write kompleksitet. Materialized views cacher komplekse query resultater. Query caching p\\u00e5 application level reducerer database load.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"OAuth 2.0 Authorization Framework\",\n",
      "            \"source\": \"RFC 6749 - The OAuth 2.0 Authorization Framework, IETF\",\n",
      "            \"content\": \"OAuth 2.0 er en authorization framework der lader third-party applications f\\u00e5 limited access til HTTP services. Det adskiller authentication fra authorization ved at bruge access tokens i stedet for credentials. OAuth definerer fire roller: resource owner (user), client (application), authorization server (authenticator), og resource server (API). Authorization code flow er mest sikker for web apps: user redirectes til authorization server, logger ind, authorization server redirecter tilbage til client med authorization code, client bytter code til access token. Implicit flow var tidligere brugt til browser-based apps men er nu deprecated til fordel for authorization code flow med PKCE. Client credentials flow bruges til server-to-server communication hvor der ikke er en user involved. Resource owner password flow giver client direkte adgang til user credentials og b\\u00f8r kun bruges i trusted applications. Access tokens er typisk short-lived mens refresh tokens er longer-lived og bruges til at f\\u00e5 nye access tokens. Scopes definerer permissions som client requester - for eksempel read:user eller write:posts. State parameter beskytter mod CSRF attacks. OAuth 2.0 specificerer ikke token format men JWT er almindeligt brugt. OpenID Connect bygger p\\u00e5 OAuth 2.0 og tilf\\u00f8jer authentication layer med ID tokens.\"\n",
      "        },\n",
      "        {\n",
      "            \"source\": \"Redis Documentation 7.0, Redis University\",\n",
      "            \"content\": \"Redis er en in-memory data structure store brugt som database, cache og message broker. Som cache reducerer Redis load p\\u00e5 prim\\u00e6r database ved at gemme frequently accessed data i hukommelsen. Data structures i Redis inkluderer strings, hashes, lists, sets, sorted sets, bitmaps og HyperLogLogs. Cache-aside pattern er mest common: application checker Redis f\\u00f8rst, ved cache miss hentes data fra database og gemmes i Redis. Write-through cache opdaterer b\\u00e5de cache og database samtidigt hvilket sikrer consistency. Write-behind cache opdaterer kun cache f\\u00f8rst og synkroniserer til database asynkront hvilket giver bedre write performance men risikerer data loss. Keys b\\u00f8r navngives konsistent med patterns som user:1234:profile. Expiration kan s\\u00e6ttes med EXPIRE kommando for automatisk at rydde gamle data. Eviction policies som LRU (Least Recently Used) styrer hvad der slettes n\\u00e5r memory er fyldt. Redis persistence options inkluderer RDB snapshots og AOF (Append Only File) logging. Redis Cluster giver horizontal scaling ved at distribuere data across multiple nodes. Pub/Sub messaging lader services subscribe til channels for real-time events. Redis Streams underst\\u00f8tter consumer groups for distributed processing. Transaction support med MULTI og EXEC sikrer atomic operations.\",\n",
      "            \"title\": \"Redis Caching Strategies\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Init VectorStore\n",
    "\n",
    "def build_vector_store():\n",
    "    url = \"https://raw.githubusercontent.com/syv-ai/it-center-fyn/main/datasets/teknologier.json\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "   \n",
    "    client = chromadb.Client()\n",
    "\n",
    "    # Option 1: Use SentenceTransformer directly (no external API needed)\n",
    "    ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "        model_name=\"intfloat/multilingual-e5-large\"\n",
    "    )\n",
    "\n",
    "    ## Option 2: Use external OpenAI-compatible embedding endpoint\n",
    "    # ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    #     api_key=\"None\",\n",
    "    #     model_name=\"intfloat/multilingual-e5-large\",\n",
    "    #     api_base=\"http://localhost:8000/v1\"   # Would point to external embedding server\n",
    "    # )\n",
    "    \n",
    "    try:\n",
    "        client.delete_collection(name=\"knowledge_base\") # Deleting collection for demo purposes\n",
    "    except Exception:\n",
    "        pass\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=\"knowledge_base\",\n",
    "        embedding_function=ef,\n",
    "        metadata={\"description\": \"Teknologier database\"}\n",
    "    )\n",
    "   \n",
    "    ids = []\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    \n",
    "    for item in data:\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        ids.append(doc_id)\n",
    "        documents.append(item[\"content\"])\n",
    "        metadatas.append({\n",
    "            \"title\": item[\"title\"],\n",
    "            \"content\": item[\"content\"],\n",
    "            \"source\": item[\"source\"]\n",
    "        })\n",
    "    print(\"Generating embeddings...\")\n",
    "    collection.add(\n",
    "        ids=ids,\n",
    "        documents=documents,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "    \n",
    "    print(f\"Inserted {len(ids)} documents into vector store\")\n",
    "    return collection\n",
    "\n",
    "collection = build_vector_store()\n",
    "results = collection.get()\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14c48d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Load .env file\n",
    "model_name=\"syvai/danskgpt-v2.1\"\n",
    "base_url = \"https://api.syv.ai/v1\" # OpenAI-compatible API inference endpoint. Ollama, vllm, etc.\n",
    "api_key = os.getenv(\"SYVAI_API_KEY\") # None required for local inference\n",
    "\n",
    "provider = OpenAIProvider(base_url=base_url, api_key=api_key)\n",
    "model = OpenAIChatModel(model_name=model_name, provider=provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "670e9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastAPI er et moderne, hurtigt web framework til at bygge APIs med Python. Det er baseret på standard Python type hints og blev skabt af Sebastián Ramírez. FastAPI er bygget oven på Starlette for web delen og Pydantic for data delen [1].\n",
      "\n",
      "Nogle af de vigtigste funktioner i FastAPI inkluderer:\n",
      "\n",
      "1. **Automatisk OpenAPI dokumentation**: FastAPI genererer automatisk OpenAPI dokumentation, der kan tilgås via /docs endpoint med Swagger UI eller /redoc for ReDoc interface [1].\n",
      "\n",
      "2. **Type hints**: Frameworket bruger Python type annotations til automatisk request validering, serialisering og dokumentation [1].\n",
      "\n",
      "3. **Asynkron programmering**: FastAPI understøtter asynkron programmering med async/await syntax, hvilket gør det ekstremt performant [1].\n",
      "\n",
      "4. **Dependency injection**: Dependency injection systemet i FastAPI gør det nemt at dele logik mellem endpoints og håndtere authentication, database connections og andre afhængigheder [1].\n",
      "\n",
      "5. **Path og query parameters**: Path parameters defineres direkte i route decorator, mens query parameters defineres som funktionsparametre [1].\n",
      "\n",
      "6. **Request body validering**: Request body validering sker automatisk gennem Pydantic models, der også bruges til response models [1].\n",
      "\n",
      "7. **Indbygget support**: FastAPI har indbygget support for WebSockets, background tasks, CORS middleware og file uploads [1].\n",
      "\n",
      "8. **Testing**: Testing af FastAPI applikationer er nemt med TestClient fra starlette.testclient [1].\n",
      "\n",
      "FastAPI er særligt velegnet til at bygge RESTful APIs, der følger de principper og konventioner, der er beskrevet i RESTful Web Services [2].\n",
      "\n",
      "Kilder:\n",
      "1. FastAPI Official Documentation 0.104, FastAPI Guide by Sebastián Ramírez\n",
      "2. RESTful Web Services, Richardson & Ruby 2007, O'Reilly Media\n"
     ]
    }
   ],
   "source": [
    "# Simple usage\n",
    "\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"\"\"Du er en dansk assistent.\n",
    "Svar direkte, korrekt og naturligt på dansk.\n",
    "Brug kun fakta og skriv et fuldt svar.\n",
    "Inkluder kildehenvisninger i teksten som [1], [2], ... og tilføj en liste over kilder til sidst.\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "query = \"Hvad er FastAPI?\"\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=3\n",
    "    )\n",
    "\n",
    "context = json.dumps(results['metadatas'][0], ensure_ascii=False, indent=2)\n",
    "\n",
    "query += \"\\n\\nSvar med kilder:\\n\\n\" + context\n",
    "\n",
    "nest_asyncio.apply()\n",
    "result = agent.run_sync(query)\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d60e0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval as tool\n",
    "\n",
    "@dataclass\n",
    "class Deps:\n",
    "    collection: Collection\n",
    "\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"\"\"Du er en dansk assistent.\n",
    "Svar direkte, korrekt og naturligt på dansk.\n",
    "Brug kun fakta og skriv et fuldt svar.\n",
    "Inkluder kildehenvisninger i teksten som [1], [2], ... og tilføj en liste over kilder til sidst.\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "@agent.tool\n",
    "async def retrieve(ctx: RunContext[Deps], search_query: str) -> str:\n",
    "    \"\"\"Søg i vores database og returner relevante kilder.\n",
    "\n",
    "Args:\n",
    "    ctx: kontekst.\n",
    "    search_query: Brugerens spørgsmål.\n",
    "\"\"\"\n",
    "\n",
    "    results = ctx.deps.collection.query(\n",
    "        query_texts=[search_query],\n",
    "        n_results=3\n",
    "    )\n",
    "    return json.dumps(results['metadatas'][0], ensure_ascii=False, indent=2)\n",
    "\n",
    "async def run_rag(query: str, history: list):\n",
    "    deps = Deps(collection=collection)\n",
    "    result = await agent.run(query, deps=deps, message_history=history)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110cc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      " Hvad er Python?\n",
      "Answer\n",
      " Python er et højniveausprogrammeringssprog, der er kendt for sin læsevenlighed og enkelhed. Det blev oprettet af Guido van Rossum og blev første gang udgivet i 1991. Python understøtter flere programmeringsparadigmer, herunder objektorienteret, imperativ og funktionel programmering. Det er et cross-platform-sprog, hvilket betyder, at det kan køre på forskellige operativsystemer som Windows, macOS og Linux.\n",
      "\n",
      "Python har en omfattende standardbibliotek, der giver adgang til systemfunktioner og opgaver som filhåndtering, netværksprogrammering og webservices. Derudover er der et stort økosystem af tredjepartsbiblioteker og -værktøjer, der udvider Python's funktioner inden for områder som videnskabelig beregning, dataanalyse, maskinlæring og webudvikling.\n",
      "\n",
      "Nogle af de mest populære biblioteker og rammer inkluderer:\n",
      "\n",
      "1. **NumPy**: Et bibliotek til numeriske beregninger og videnskabelig computing.\n",
      "2. **Pandas**: Et bibliotek til dataanalyse og -manipulation.\n",
      "3. **Matplotlib og Seaborn**: Biblioteker til datavisualisering.\n",
      "4. **Django og Flask**: Rammer til webudvikling.\n",
      "5. **Scikit-learn**: Et bibliotek til maskinlæring.\n",
      "6. **TensorFlow og PyTorch**: Biblioteker til dyb lærings- og neurale netværksmodeller.\n",
      "\n",
      "Python's syntaks er designet til at være intuitiv og let at læse, hvilket gør det til et populært valg for både begyndere og erfarne programmører. Det er også et dynamisk sprog, hvilket betyder, at der ikke er behov for at deklarere variabeltyper eksplisitt.\n",
      "\n",
      "Python har en stor og aktiv community, der bidrager til dets udvikling og vedligeholdelse. Det er et open-source-projekt, og koden er tilgængelig på GitHub. Python's popularitet og bredde af anvendelser gør det til et værdifuldt værktøj for programmører i mange forskellige områder.\n",
      "\n",
      "For mere information om Python, kan du besøge den officielle Python-website: [Python.org](https://www.python.org/) [1].\n",
      "\n",
      "### Kilder\n",
      "1. [Python.org](https://www.python.org/)\n",
      "Usage\n",
      " RunUsage(input_tokens=161, output_tokens=543, requests=1)\n",
      "\n",
      "Question\n",
      " Hvad spurgte jeg lige før?\n",
      "Answer\n",
      " Du spurgte lige før, hvad Python er.\n",
      "Usage\n",
      " RunUsage(input_tokens=716, output_tokens=13, requests=1)\n"
     ]
    }
   ],
   "source": [
    "# Chat history management\n",
    "history = []\n",
    "\n",
    "query = \"Brug retrieve værktøjet til dette spørgsmål: Hvad er Python?\" # Explicitly use tool, not needed depending on model & setup\n",
    "result_1 = await run_rag(query, history)\n",
    "history = result_1.all_messages()\n",
    "print(\"Question\\n\", query)\n",
    "print(\"Answer\\n\", result_1.output)\n",
    "print(\"Usage\\n\", result_1.usage())\n",
    "\n",
    "query = \"Hvad spurgte jeg om lige før?\"\n",
    "result_2 = await run_rag(query, history)\n",
    "history = result_2.all_messages()# Update history again\n",
    "print(\"\\nQuestion\\n\", query)\n",
    "print(\"Answer\\n\", result_2.output)\n",
    "print(\"Usage\\n\", result_2.usage())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
